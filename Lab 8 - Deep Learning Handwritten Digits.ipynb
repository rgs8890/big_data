{"cells":[{"cell_type":"markdown","metadata":{"id":"xBSJgdQdeL4V"},"source":["# Lab Sheet 8: Deep Learning handwritten digits classification with CNNs\n","\n","This lab is about creating a (moderately) **deep convolutional neural network (CNN)** to classify digits from the **MNIST dataset**.\n","\n","In this notebook, we'll use **Tensorflow** library with the  **Keras** frontend.  \n","\n","Since this is new, this notebook **can be mostly run as is in 1) to 4)**. Once you have run it, please try the following:\n","## Task a)\n","**Increase** the number of **convolutional layers**. See details in section 2).\n","## Task b)\n","Test the notebook **with and without GPU or TPU** (in the Menu under *Runtime* ➡︎ *Change Runtime Type*).\n","\n","\n","## Task c)\n","Optional: **Vertex AI**, ([here](https://cloud.google.com/ai-platform) is some general information)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zaawHSDmgC1e"},"source":["# MNIST digit classification with a CNN"]},{"cell_type":"markdown","metadata":{"id":"8G3UI45usO3w"},"source":["First, we need a number of **imports**."]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"kZUJ0t101eQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PU7oPJ-JeL4a"},"outputs":[],"source":["%matplotlib inline\n","\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Conv2D\n","#from tensorflow.keras.estimator import model_to_estimator\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import backend as K\n","\n","from distutils.version import LooseVersion as LV\n","from IPython.display import SVG\n","from tensorflow.keras.utils import model_to_dot\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"]},{"cell_type":"markdown","metadata":{"id":"VRyhDjyteL4m"},"source":["# 1) Loading and preparing data\n","\n","Now we load the MNIST or [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. We will create a one-hot encoded version of the labels, which works better for training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGsfbOozeL4o"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist, fashion_mnist\n","# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# The following line loads the Fashion-MNIST instead of the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n","nb_classes = 10 # digits 0-9 or different clothing types\n","\n","X_train = X_train.astype('float32') # this is the normal type for Neural Networks\n","X_test = X_test.astype('float32') # a good compromise between efficiency and resolution\n","X_train /= 255 # reduce the range to [0,1]\n","X_test /= 255 # also for the test set\n","\n","# one-hot encoding:\n","Y_train = to_categorical(y_train, nb_classes) # one-hot means that each class corresponds to a vector dimension\n","Y_test = to_categorical(y_test, nb_classes) # that is set to 1, all others are set to 0\n","\n","print() # print some info on the data\n","print('MNIST data loaded: train:', len(X_train), 'test:', len(X_test))\n","print('X_train:', X_train.shape)\n","print('y_train:', y_train.shape)\n","print('Y_train:', Y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"KpnSjHo7eL4t"},"source":["We have to do a bit of tensor manipulation, so that the data matches the shape expected by the 2D convolutional layer implementation in tensorflow: # of images, height, width, channels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jc5mryweL4u"},"outputs":[],"source":["# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","print('X_train:', X_train.shape)\n","print('X_test:', X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"z4eef0rteL4x"},"source":["# 2) Creating the CNN model\n","\n","Now we are ready to create a convolutional model.\n","\n"," * The `Convolution2D` layers operate on 2D matrices so we input the digit images directly to the model.  \n"," * The `MaxPooling2D` layer reduces the spatial dimensions, that is, makes the image smaller.\n"," * The `Flatten` layer flattens the 2D matrices into vectors, so we can then switch to  `Dense` layers as in standard neural network.\n","\n","See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERbeuo0CeL4y"},"outputs":[],"source":["# number of convolutional filters to use\n","nb_filters = 32\n","# convolution kernel size\n","kernel_size = (3, 3)\n","# size of pooling area for max pooling\n","pool_size = (2, 2)\n","\n","model = Sequential()\n","\n","# Convolutional layer(s)\n","model.add(Conv2D(nb_filters, kernel_size,\n","                 padding='valid',\n","                 input_shape=input_shape,\n","                 activation='relu'))\n","model.add(MaxPooling2D(pool_size=pool_size))\n","model.add(Dropout(rate=0.25))\n","\n","# Dense layers\n","model.add(Flatten())\n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(units=nb_classes, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print(model.summary())\n","\n","\n"]},{"cell_type":"code","source":["!pip install pydot\n","!apt-get install graphviz -y"],"metadata":{"id":"B9Xi1yQD1luP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7gMZ7fyeL41"},"outputs":[],"source":["SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"]},{"cell_type":"markdown","metadata":{"id":"sc6HgaJHgwwk"},"source":["## Task a)\n","Once you have tested the whole notebook, increase the number of convolutional layers. Try 2 and 3 layers.\n","This can be achieved by adding another `Conv2D` layer after the first one with `model.add()`.\n","This can can have the same arguments as the first one. The shapes of the layers are determined automatically, as you can see in the model summary.\n","What is the effect on the training time and accuracy?"]},{"cell_type":"markdown","metadata":{"id":"0ULkNaggeL44"},"source":["# 3) Training\n","\n","Now we **train** the CNN **model**.\n","\n","This is a relatively complex model, so training takes a short while, but it **benefits** considerably from a **GPU** or **TPU**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbN1YylBeL45"},"outputs":[],"source":["%%time\n","\n","epochs = 15 # with CPU one epoch takes about 15 seconds (on MNIST)\n","# with GPU one epoch takes only a few seconds, depending on the number of layers\n","\n","history = model.fit(X_train,\n","                    Y_train,\n","                    epochs=epochs,\n","                    batch_size=128,\n","                    verbose=2)"]},{"cell_type":"markdown","metadata":{"id":"Osyr1DFDhyvr"},"source":["We can now **plot** the training loss and accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIStCeiceL47"},"outputs":[],"source":["plt.figure(figsize=(5,3))\n","plt.plot(history.epoch, history.history['loss'])\n","plt.title('loss')\n","\n","plt.figure(figsize=(5,3))\n","plt.plot(history.epoch, history.history['accuracy'])\n","plt.title('accuracy');"]},{"cell_type":"markdown","metadata":{"id":"_bdhwZ6YWN1i"},"source":["If we are happy with the model, let's save it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43EVShVIWOOP"},"outputs":[],"source":["model.save('model.keras')"]},{"cell_type":"markdown","metadata":{"id":"iRh64AE2eL49"},"source":["# 4) Inference\n","\n","We now **use the trained model** on the test set. The test accuracy will be almost 99% for MNIST and 91% for Fasion-MNIST.  \n","\n","You can compare your MNIST result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354).  Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiUfC8n8eL4-"},"outputs":[],"source":["%%time\n","scores = model.evaluate(X_test, Y_test, verbose=2)\n","print(\"{}: {:.2f}%\".format(model.metrics_names[1], scores[1]*100))"]},{"cell_type":"markdown","metadata":{"id":"a1k2ykDqeL5A"},"source":["We can again take a closer look on the results. We begin by defining\n","a helper function to **show the failure cases** of our classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3vmwlhYeL5A"},"outputs":[],"source":["def show_failures(predictions, trueclass=None, predictedclass=None, maxtoshow=10):\n","    rounded = np.argmax(predictions, axis=1)\n","    errors = rounded!=y_test\n","    print('Showing max', maxtoshow, 'first failures. '\n","          'The predicted class is shown first and the correct class in parenthesis.')\n","    ii = 0\n","    plt.figure(figsize=(maxtoshow, 1))\n","    for i in range(X_test.shape[0]):\n","        if ii>=maxtoshow:\n","            break\n","        if errors[i]:\n","            if trueclass is not None and y_test[i] != trueclass:\n","                continue\n","            if predictedclass is not None and rounded[i] != predictedclass:\n","                continue\n","            plt.subplot(1, maxtoshow, ii+1)\n","            plt.axis('off')\n","            if K.image_data_format() == 'channels_first':\n","                plt.imshow(X_test[i,0,:,:], cmap=\"gray\")\n","            else:\n","                plt.imshow(X_test[i,:,:,0], cmap=\"gray\")\n","            plt.title(\"%d (%d)\" % (rounded[i], y_test[i]))\n","            ii = ii + 1"]},{"cell_type":"markdown","metadata":{"id":"4JJuNNwheL5D"},"source":["Here are the first 10 test examples the CNN **classified to a wrong class**:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLEKq0sueL5E","scrolled":true},"outputs":[],"source":["predictions = model.predict(X_test)\n","\n","show_failures(predictions)"]},{"cell_type":"markdown","metadata":{"id":"hnR0Egpv-CkT"},"source":["Note that the labels for Fashion-MNIST correspond to 0: T-shirt/top, 1: Trouser, 2: Pullover, 3: Dress, 4: Coat, 5: Sandal, 6: Shirt, 7: Sneaker, 8: Bag, 9: Ankle boot."]},{"cell_type":"markdown","metadata":{"id":"H_4FH2aEeL5F"},"source":["We can use `show_failures()` to inspect failures in more detail. For example, I get some cases in which the **true class was \"6\" but the prediction a \"0\"**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSG_7X11eL5G"},"outputs":[],"source":["show_failures(predictions, trueclass=6, predictedclass=0)"]},{"cell_type":"markdown","metadata":{"id":"jzl6YQCGEuFj"},"source":["# 5) Vertex AI (Optional)\n","\n","If you are interested in Vertex AI, have a look here: https://cloud.google.com/vertex-ai"]}],"metadata":{"accelerator":"TPU","colab":{"private_outputs":true,"provenance":[{"file_id":"1yGiOzo3BKQCLWswoySqY3je4YhZyfA5D","timestamp":1582916726875},{"file_id":"https://github.com/csc-training/intro-to-dl/blob/master/day1/keras-mnist-cnn.ipynb","timestamp":1553226422877}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}